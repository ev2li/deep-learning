{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step1. 导入相关包\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Step2. 加载数据集\n",
    "dataset = load_dataset(\"csv\", data_files=\"./ChnSentiCorp_htl_all.csv\", split=\"train\")\n",
    "dataset = dataset.filter(lambda x: x[\"review\"] is not None)\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step3. 划分数据集\n",
    "datasets = dataset.train_test_split(test_size=0.1)\n",
    "datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step4. 数据预处理\n",
    "\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")\n",
    "\n",
    "def process_function(examples):\n",
    "    tokenzed_examples = tokenizer(examples[\"review\"], max_length=128, truncation=True)\n",
    "    tokenzed_examples[\"labels\"] = examples[\"labels\"]\n",
    "    return tokenzed_examples\n",
    "\n",
    "tokenized_datasets = datasets.map(process_function, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step5. 创建模型\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hfl/rbt3\")\n",
    "\n",
    "# Step6. 创建评估函数\n",
    "import evaluate\n",
    "acc_metrics = evaluate.load(\"accuracy\")\n",
    "f1_metrics = evaluate.load(\"f1\")\n",
    "\n",
    "def eval_metric(eval_predict):\n",
    "    predictions, labels = eval_predict\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    acc = acc_metrics.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metrics.compute(predictions=predictions, references=labels)\n",
    "    acc.update(f1)\n",
    "    return  acc\n",
    "\n",
    "# Step7. 创建TrainingArguments\n",
    "train_args = TrainingArguments(output_dir=\"./checkpoints\", per_device_train_batch_size=64, per_device_eval_batch_size=128,logging_steps=10, evaluation_strategy=\"steps\", eval_steps=110,save_strategy=\"epoch\", save_total_limit=3,learning_rate=2e-5, weight_decay=0.01)\n",
    "train_args\n",
    "\n",
    "# Step8. 创建Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "trainer = Trainer(model=model, args=train_args,train_dataset=tokenized_datasets[\"train\"], eval_dataset=tokenized_datasets[\"test\"], data_collator=DataCollatorWithPadding(tokenizer=tokenizer),compute_metrics=eval_metric)\n",
    "\n",
    "# Step9. 模型训练\n",
    "trainer.train()\n",
    "\n",
    "# Step10. 模型评估\n",
    "trainer.evaluate()\n",
    "\n",
    "# Step11. 模型预测\n",
    "trainer.predict(tokenized_datasets[\"test\"])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
