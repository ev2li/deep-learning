{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# sentiment analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. tokenizer 构造输入\n",
    "- tokenizer,model:相匹配, tokenizer的outputs作为model的input\n",
    "- Auto*Tokenizer: Auto*Model: Generic type\n",
    "- tokenizer:服务于model的input\n",
    "    - len(input_ids) == len(attention_mask)\n",
    "    - tokenizer(test_sentences[0],):tokenizer.__call__:encode\n",
    "    - tokenizer.encode == tokenizer.tokenize + tokenizer.convert_tokens_to_ids\n",
    "    - tokenizer.decode\n",
    "    - tokenizer：工作原理其实就是tokenizer.vocab：字典，存储了token与id的映射\n",
    "        - tokenizer.special_tokens_map\n",
    "    - attention mask与padding相匹配"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "test_senteces = [\"today is not that bat\", \"today is so bad\"]\n",
    "model_name = \"distrilbert-base-uncased-finetuned-sst-2-english\"\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_inputs = tokenizer(test_senteces, truncation=True, padding=True,return_tensors=\"pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.encode(test_senteces)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.tokenize(test_senteces)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(test_senteces))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenizer.encode(test_senteces))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.vocab #词典"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.vocab_size #词典长度"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.specials_tokens_map.values()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids([special for special in tokenizer.specials_tokens_map.values()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer(test_senteces, max_length=32,truncation=True,padding=\"max_length\", return_tensor=\"pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. model 调用模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad:\n",
    "    outputs = model(**batch_inputs)\n",
    "    print(outputs)\n",
    "    scores = F.softmax(outputs.logits, dim=1)\n",
    "    print(scores)\n",
    "    labels = torch.argmax(scores, dim=1)\n",
    "    labels = [model.config.id2label[id] for id in labels.tolist()]\n",
    "    print(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. parse output输出解析"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad:\n",
    "    outputs = model(**batch_inputs)\n",
    "    print(outputs)\n",
    "    scores = F.softmax(outputs.logits, dim=1)\n",
    "    print(scores)\n",
    "    labels = torch.argmax(scores, dim=1)\n",
    "    labels = [model.config.id2label[id] for id in labels.tolist()]\n",
    "    print(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
