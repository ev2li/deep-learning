{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 人名分类问题：\n",
    "- 以一个人名为输入，使用模型帮助我们判断它最有可能是来自哪一个国家的人名，这在某些国际化公司的业务中具有重要意义，在用户注册过程中，会根据用户填写的名字直接给他分配可能的国家或地区选项，以及该国家或地区的国旗，限制手机号吗位数等等\n",
    "\n",
    "## 整个案例分为5个步骤\n",
    "- 第一步：导入必要的工具包\n",
    "- 第二步: 对data文件中的数据进行处理，满足训练要求\n",
    "- 第三步: 构建RNN模型(包括传统的RNN,LSTM以及GRU等)\n",
    "- 第四步：构建训练函数并进行训练\n",
    "- 第五步：构建评估函数并进行预测"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_letter: 57\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "#  第一步：导入必要的工具包\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "import random\n",
    "import time\n",
    "import match\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 第二步：对data文件中的数据进行处理，满足训练要求\n",
    "# 获取所有的常用字符包括字母和常用标点\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "# 获取常用字符数量\n",
    "n_letters = len(all_letters)\n",
    "print(\"n_letter:\", n_letters)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T14:08:43.198705Z",
     "end_time": "2023-06-14T14:08:46.821304Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "# 关于编码问题我们暂且不去考虑\n",
    "# 我们认为这个函数的作用就是去掉一些语言中的重音标记\n",
    "# 如: Ślusàrski ---> Slusarski\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "# 调用\n",
    "s = \"Ślusàrski\"\n",
    "a = unicodeToAscii(s)\n",
    "print(a)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T14:08:46.824421Z",
     "end_time": "2023-06-14T14:08:46.829214Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ang', 'AuYong', 'Bai', 'Ban', 'Bao', 'Bei', 'Bian', 'Bui', 'Cai', 'Cao', 'Cen', 'Chai', 'Chaim', 'Chan', 'Chang', 'Chao', 'Che', 'Chen', 'Cheng', 'Cheung', 'Chew', 'Chieu', 'Chin', 'Chong', 'Chou', 'Chu', 'Cui', 'Dai', 'Deng', 'Ding', 'Dong', 'Dou', 'Duan', 'Eng', 'Fan', 'Fei', 'Feng', 'Foong', 'Fung', 'Gan', 'Gauk', 'Geng', 'Gim', 'Gok', 'Gong', 'Guan', 'Guang', 'Guo', 'Gwock', 'Han', 'Hang', 'Hao', 'Hew', 'Hiu', 'Hong', 'Hor', 'Hsiao', 'Hua', 'Huan', 'Huang', 'Hui', 'Huie', 'Huo', 'Jia', 'Jiang', 'Jin', 'Jing', 'Joe', 'Kang', 'Kau', 'Khoo', 'Khu', 'Kong', 'Koo', 'Kwan', 'Kwei', 'Kwong', 'Lai', 'Lam', 'Lang', 'Lau', 'Law', 'Lew', 'Lian', 'Liao', 'Lim', 'Lin', 'Ling', 'Liu', 'Loh', 'Long', 'Loong', 'Luo', 'Mah', 'Mai', 'Mak', 'Mao', 'Mar', 'Mei', 'Meng', 'Miao', 'Min', 'Ming', 'Moy', 'Mui', 'Nie', 'Niu', 'OuYang', 'OwYang', 'Pan', 'Pang', 'Pei', 'Peng', 'Ping', 'Qian', 'Qin', 'Qiu', 'Quan', 'Que', 'Ran', 'Rao', 'Rong', 'Ruan', 'Sam', 'Seah', 'See ', 'Seow', 'Seto', 'Sha', 'Shan', 'Shang', 'Shao', 'Shaw', 'She', 'Shen', 'Sheng', 'Shi', 'Shu', 'Shuai', 'Shui', 'Shum', 'Siew', 'Siu', 'Song', 'Sum', 'Sun', 'Sze ', 'Tan', 'Tang', 'Tao', 'Teng', 'Teoh', 'Thean', 'Thian', 'Thien', 'Tian', 'Tong', 'Tow', 'Tsang', 'Tse', 'Tsen', 'Tso', 'Tze', 'Wan', 'Wang', 'Wei', 'Wen', 'Weng', 'Won', 'Wong', 'Woo', 'Xiang', 'Xiao', 'Xie', 'Xing', 'Xue', 'Xun', 'Yan', 'Yang', 'Yao', 'Yap', 'Yau', 'Yee', 'Yep', 'Yim', 'Yin', 'Ying', 'Yong', 'You', 'Yuan', 'Zang', 'Zeng', 'Zha', 'Zhan', 'Zhang', 'Zhao', 'Zhen', 'Zheng', 'Zhong', 'Zhou', 'Zhu', 'Zhuo', 'Zong', 'Zou', 'Bing', 'Chi', 'Chu', 'Cong', 'Cuan', 'Dan', 'Fei', 'Feng', 'Gai', 'Gao', 'Gou', 'Guan', 'Gui', 'Guo', 'Hong', 'Hou', 'Huan', 'Jian', 'Jiao', 'Jin', 'Jiu', 'Juan', 'Jue', 'Kan', 'Kuai', 'Kuang', 'Kui', 'Lao', 'Liang', 'Lu', 'Luo', 'Man', 'Nao', 'Pian', 'Qiao', 'Qing', 'Qiu', 'Rang', 'Rui', 'She', 'Shi', 'Shuo', 'Sui', 'Tai', 'Wan', 'Wei', 'Xian', 'Xie', 'Xin', 'Xing', 'Xiong', 'Xuan', 'Yan', 'Yin', 'Ying', 'Yuan', 'Yue', 'Yun', 'Zha', 'Zhai', 'Zhang', 'Zhi', 'Zhuan', 'Zhui']\n"
     ]
    }
   ],
   "source": [
    "# 构建一个从持久化文件中读取内容到内存的函数\n",
    "data_path = \"./data/names/\"\n",
    "\n",
    "def readLines(filename):\n",
    "    \"\"\"从文件中读取每一行加载到内存中形成列表\"\"\"\n",
    "    # 打开指定文件并读取所有内容, 使用strip()去除两侧空白符, 然后以'\\n'进行切分\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    # 对应每一个lines列表中的名字进行Ascii转换, 使其规范化.最后返回一个名字列表\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "# filename是数据集中某个具体的文件, 我们这里选择Chinese.txt\n",
    "filename = data_path + \"Chinese.txt\"\n",
    "lines = readLines(filename)\n",
    "print(lines)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T14:12:28.330307Z",
     "end_time": "2023-06-14T14:12:28.355682Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 构建人名类别(所属的语言)列表和人名对应关系字典"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_categories: 18\n"
     ]
    }
   ],
   "source": [
    "# 构建的category_lines形如：{\"English\":[\"Lily\", \"Susan\", \"Kobe\"], \"Chinese\":[\"Zhang San\", \"Xiao Ming\"]}\n",
    "category_lines = {}\n",
    "# all_categories形如： [\"English\",...,\"Chinese\"]\n",
    "all_categories = []\n",
    "\n",
    "# 读取指定路径下的txt文件，使用glob,path中可以使用正则表达式\n",
    "for filename in glob.glob(data_path + \"*.txt\"):\n",
    "    # 获取每个文件的文件名，就是对应的名字类别\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    # 将其逐一加到all_categories列表中\n",
    "    all_categories.append(category)\n",
    "    # 然后读取每个文件的内容，形成名字列表\n",
    "    lines = readLines(filename)\n",
    "    # 按照对应的类别，将名字列表写入到catagory_lines字典中\n",
    "    category_lines[category] = lines\n",
    "\n",
    "# 查看类别总数\n",
    "n_categories = len(all_categories)\n",
    "print(\"n_categories:\", n_categories)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T14:28:52.056103Z",
     "end_time": "2023-06-14T14:28:52.125734Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
     ]
    }
   ],
   "source": [
    "# 随便查看其中的一些内容\n",
    "print(category_lines['Italian'][:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T14:34:02.880920Z",
     "end_time": "2023-06-14T14:34:02.903555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_tensor: tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# 将人名转化为对应的one-hot张量表示\n",
    "# 将字符串(单词粒度)转化为张量表示，如：\"ab\" --->\n",
    "# tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "#          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "#          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "#          0., 0., 0., 0., 0., 0.]],\n",
    "\n",
    "#        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "#          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "#          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "#          0., 0., 0., 0., 0., 0.]]])\n",
    "def lineToTensor(line):\n",
    "    \"\"\"将人名转化为对应的one-hot张量表示，参数line是输入的人名\"\"\"\n",
    "    # 首先初始化一个0张量，它的形状(len(line), 1, n_letters)\n",
    "    # 代表人名中的每个字母用一个1 x n_letters的张量表示\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    # 遍历这个人名中的每个字符索引和字符\n",
    "    for li, letter in enumerate(line):\n",
    "        # 使用字符串方法find找到每个字符在all_letters中的索引\n",
    "        # 它也是我们生成one-hot张量中1的索引位置\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    # 返回结果\n",
    "    return  tensor\n",
    "\n",
    "\n",
    "line = \"Bai\"\n",
    "line_tensor = lineToTensor(line)\n",
    "print(\"line_tensor:\", line_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T14:41:10.920248Z",
     "end_time": "2023-06-14T14:41:10.989334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 构建传统RNN模型\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        \"\"\"初始化函数中有4个参数，分别代表RNN输入最后一维尺寸，RNN隐层最后一维尺寸,RNN层数\"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        # 将hidden_size与num_layers传入其中\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 实例化预定义的nn.RNN,它的三个参数分别是input_size，hidden_size, num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers)\n",
    "        # 实例化nn.Linear,这个线性层用于将nn.RNN的输出值维度转化为指定的输出维度\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        # 实例化nn中预定的Softmax层，用于从输出层获得类别结果\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"完成传统RNN的主要逻辑，输入参数input代表输入张量，它的形状是1 x n_letters\n",
    "        hidden代表RNN的隐层张量，它的形状是self.num_layers x 1 x self.hidden_size\"\"\"\n",
    "        # 因此预定义的nn.RNN要求输入维度一定是三维张量，因此在这里使用unsqueeze(0)扩展一个维度\n",
    "        input = input.unsqueeze(0)\n",
    "        # 将input和hidden输入到传统RNN的实例化对象中，如果num_layers = 1，rr恒等于hn\n",
    "        rr, hn = self.rnn(input, hidden)\n",
    "        # 将从RNN中获得的结果通过线性变换和softmax返回，同时返回hn作为后续RNN的输入\n",
    "        return self.softmax(self.linear(rr)), hn\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"初始化隐层张量\"\"\"\n",
    "        # 初始化一个(self.num_layers, 1, self.hidden_size)形状为0的张量\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T14:59:03.735388Z",
     "end_time": "2023-06-14T14:59:03.789147Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2, 3, 4]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze演示\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "torch.unsqueeze(x, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T14:59:53.469232Z",
     "end_time": "2023-06-14T14:59:53.579673Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1],\n        [2],\n        [3],\n        [4]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(x, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T15:00:03.670901Z",
     "end_time": "2023-06-14T15:00:03.714746Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 构建LSTM模型\n",
    "# 使用nn.LSTM构建完成LSTM使用类\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        # 初始化函数的参数与传统RNN相同\n",
    "        super(LSTM, self).__init__()\n",
    "        # 将hidden_size与num_layers传入其中\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 实例化预定义的nn.LSTM\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        # 实例化nn.Linear,这个线性层用于将nn.RNN的输出维度转化为指定的输出维度\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        # 实例化nn中预定的Softmax层，用于从输出层获得类别结果\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, input, hidden, c):\n",
    "        \"\"\"在主要逻辑函数中多出一个参数c, 也就是LSTM中的细胞状态张量\"\"\"\n",
    "        # 使用unsqueeze(0)扩展一个维度\n",
    "        input = input.unsqueeze(0)\n",
    "        # 将input, hidden以及初始化的c传入lstm中\n",
    "        rr, (hn, c) = self.lstm(input, (hidden, c))\n",
    "        # 最后返回处理后rr, hn, c\n",
    "        return self.softmax(self.linear(rr)), hn, c\n",
    "\n",
    "    def initHiddenAndC(self):\n",
    "        \"\"\"初始化函数不仅初始化hidden还要初始化细胞状态c，它们的形状相同\"\"\"\n",
    "        c = hidden = torch.zeros(self.num_layers, 1, self.hidden_size)\n",
    "        return  hidden, c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T15:13:45.863570Z",
     "end_time": "2023-06-14T15:13:45.907037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 构建GRU模型\n",
    "# 使用nn.GRU构建完成传统RNN使用类\n",
    "\n",
    "# GRU与传统RNN的外部形式相同, 都是只传递隐层张量, 因此只需要更改预定义层的名字\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 实例化预定义的nn.GRU, 它的三个参数分别是input_size, hidden_size, num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers)\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.unsqueeze(0)\n",
    "        rr, hn = self.gru(input, hidden)\n",
    "        return self.softmax(self.linear(rr)), hn\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-14T15:31:44.877276Z",
     "end_time": "2023-06-14T15:31:44.934377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
