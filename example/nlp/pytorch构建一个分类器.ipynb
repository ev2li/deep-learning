{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### 分类器任务和数据介绍\n",
    "\n",
    "- 构造一个将不同图像进行分类的神经网络分类器，对输入的图片进行判别并完成分类\n",
    "\n",
    "- 本案例采用CIFAR10数据集作为原始的图片数据\n",
    "\n",
    "- CIFAR10数据集介绍:数据集中每张图片的尺寸是3x32x32代表彩色3通道\n",
    "\n",
    "- CIFAR10数据集总共有10种不同的分类，分别是\"airplane\", \"automobile\". \"bird\", \"cat\", \"deer\". \"dog\", \"frog\", \"horse\", \"ship\", \"truck\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 训练分类器的步骤\n",
    "\n",
    "- 使用torchvision下载CIFAR10数据集\n",
    "- 定义卷积神经网络\n",
    "- 定义损失函数\n",
    "- 在训练集上训练模型\n",
    "- 在测试集上测试模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T15:11:02.340302Z",
     "end_time": "2023-06-07T15:11:02.348192Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 下载数据集并将图片进行调整，因为torchvision数据集的输出是PILImage格式，数据域在[0,1]，我们将其转换为标准数据域[-1,1]的张量格式"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/170498071 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c34b66a412644f97a3897b307ffbcaf4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#torchvision数据集的输出是PILImage格式，数据域在[0,1]，我们将其转换为标准数据域[-1,1]的张量格式\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T15:17:12.129381Z",
     "end_time": "2023-06-07T15:17:43.643272Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 注意\n",
    "- 如果你是在Windows系统下运行上述代码，并且出现报错信息\"BrokenPipeError\",可以尝试将torch.utils.data.DataLoader()中的num_workers设置为0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 展示若干训练集的图片\n",
    "# 导入画图包和numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 构建展示图片的函数\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 从数据迭代器中读取一张图片\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.__next__()\n",
    "\n",
    "# 展示图片\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 打印标签label\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 定义卷积神经网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __int__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # 变换x的形状以适配全连接层的输入\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T16:21:05.325223Z",
     "end_time": "2023-06-07T16:21:05.333436Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.定义损失函数\n",
    "- 采用交叉熵损失函数和随机梯度下降优化器"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4.在训练集上训练模型\n",
    "- 采用基于梯度下降的优化算法，都需要很多个轮次的迭代训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <DDABACEB-F2EA-368C-80DD-40745DFB96F8> /Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <2729F3D6-2C8E-3DA6-9E14-4070A60558E5> /Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <DDABACEB-F2EA-368C-80DD-40745DFB96F8> /Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <2729F3D6-2C8E-3DA6-9E14-4070A60558E5> /Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m inputs, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# 首先将优化器梯度归零\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# 输入图像张量进网络，得到输出张量outputs\u001B[39;00m\n\u001B[1;32m     11\u001B[0m outputs \u001B[38;5;241m=\u001B[39m net(inputs)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    # 按批次迭代训练模型\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 从data中取出含有输入图像张量inputs，标签张量labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 第一步:首先将优化器梯度归零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 第二步: 输入图像张量进入网络中，得到输出张量outputs\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        #  利用网络的输出outputs和标签labels计算损失值\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播+参数更新，是标准代码的标准流程\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印轮次和损失值\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 保存模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# 首先设定模型的保存路径\n",
    "PATH = './cifar_net.pth'\n",
    "# 保存模型的状态字典\n",
    "torch.save(net.state_dict(), PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T17:00:52.592185Z",
     "end_time": "2023-06-07T17:00:52.677077Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 5.在测试集上测试模型\n",
    "- 第一步:展示测试集中的若干图片"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <DDABACEB-F2EA-368C-80DD-40745DFB96F8> /Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <2729F3D6-2C8E-3DA6-9E14-4070A60558E5> /Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <DDABACEB-F2EA-368C-80DD-40745DFB96F8> /Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <2729F3D6-2C8E-3DA6-9E14-4070A60558E5> /Users/zhangli/anaconda3/envs/deep-learning/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_MultiProcessingDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m dataiter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(testloader)\n\u001B[0;32m----> 2\u001B[0m images, labels \u001B[38;5;241m=\u001B[39m \u001B[43mdataiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# 打印原始图片\u001B[39;00m\n\u001B[1;32m      5\u001B[0m imshow(torchvision\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mmake_grid(images))\n",
      "\u001B[0;31mAttributeError\u001B[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 打印原始图片\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# 打印真实标签\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 加载模型并对测试图片进行预测"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 首先实例化模型的类对象\n",
    "net = Net()\n",
    "# 加载训练阶段保存好的模型状态字典\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# 利用模型对图片进行预测\n",
    "outputs = net(images)\n",
    "\n",
    "# 共有10个类别，采用模型计算出的概率最大的作为预测的类别\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# 打印预测标签的结果\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 全部测试集上的表现\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' %(100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 为了更加细致的看一下模型在哪些类别上表现的更好，在哪些类别上表现的更差，我们分类别进行准确率计算"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "print(class_correct)\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s: %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-07T17:52:28.120519Z",
     "end_time": "2023-06-07T17:52:28.191764Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 当训练模型的时候，只需要将模型转移到GPU上，同时将输入的图片和标签页转移到GPU上即可"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 将模型转移到GPU上\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "# 将输入的图片张量和标签张量转移到GPU上\n",
    "inputs, labels = data[0].to(device), data[1].to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
